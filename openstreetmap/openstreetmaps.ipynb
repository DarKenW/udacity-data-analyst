{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Wrangle OpenStreetMaps Data\n",
    "================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step One - Finish Lession 6\n",
    "-------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Done."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step Two - Review the Rubric and Sample Project\n",
    "--------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Done."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step Three - Choose Your Map Area\n",
    "-------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use [Map Zen](https://mapzen.com/data/metro-extracts) to download the preselected metro area of San Francisco, California. After uncompressing, the dataset size is 648.9MB."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step Four - Process your Dataset\n",
    "------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Audit the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sanity check on element types\n",
    "\n",
    "As a sanity check, we go through the dataset to see list all element types, which should contain the following:\n",
    "  * `osm`: top-level root node\n",
    "  * `node`, `way` and `relation`: instances of data primitives\n",
    "  * `tag`: a general purpose node for key/value pair.\n",
    "  * `nd`: used inside `way`s to reference a `node` element.\n",
    "  * `member`: used inside a `relation`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set(['node', 'nd', 'bounds', 'member', 'tag', 'relation', 'way', 'osm'])\n"
     ]
    }
   ],
   "source": [
    "import xml.etree.cElementTree as ET\n",
    "\n",
    "xml_file = \"data/san-francisco_california.osm\"\n",
    "elem_types = set()\n",
    "for _, elem in ET.iterparse(xml_file):\n",
    "    # If the element type is not seen before, add it to the set.\n",
    "    if elem.tag not in elem_types:\n",
    "        elem_types.add(elem.tag)\n",
    "\n",
    "print elem_types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The only \"unexpected\" element type is `bounds`, which occurs only once in the dataset to indicate the bounding box of this dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Street address types\n",
    "\n",
    "Next we try to see different address types of all elements, and how many times each address type appears in the dataset. The address type is found from the `<tag k=\"addr:XXX\" v=\"xxxxxx\">` tag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "housenumber : 47790\n",
      "city : 44022\n",
      "street : 40586\n",
      "postcode : 9503\n",
      "state : 3224\n",
      "country : 1262\n",
      "county : 374\n",
      "interpolation : 317\n",
      "housename : 293\n",
      "unit : 56\n",
      "full : 43\n",
      "paloaltoca_id : 43\n",
      "housenumber:source : 3\n",
      "street:source : 2\n",
      "floor : 2\n",
      "suite : 2\n",
      "pier : 1\n",
      "province : 1\n",
      "1:housenumber : 1\n",
      "place : 1\n",
      "door : 1\n"
     ]
    }
   ],
   "source": [
    "import operator\n",
    "\n",
    "address_types = {}\n",
    "for _, tag in ET.iterparse(xml_file):\n",
    "    if tag.tag == \"tag\" and tag.attrib['k'].startswith(\"addr:\"):\n",
    "        k = tag.attrib['k'][5:]\n",
    "        address_types.setdefault(k, 0)\n",
    "        address_types[k] += 1\n",
    "\n",
    "for k,v in sorted(address_types.items(), key=operator.itemgetter(1), reverse=True):\n",
    "    print k, ':', v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see the majority of address types are `housenumber`(47790), `city`(44022), `street`(40586) and `postcode`(9503), and the relatively rare address types are `housenumber:source`, `street:source`, `floor`, `suite`, `pier`, `province`, `1:housenumber`, `place`, `door`, which happens only once or twice in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Street names\n",
    "\n",
    "After having the street address types, we try to audit all the street name in the dataset. Street name is extracted as the last word of `<tag k=\"addr:street\" v=\"xxxxxx\">` tag. We also keep a small number of examples for each street name type during the auditing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "street : 15350 [ Haight Street, Haight Street, Haight Street ,...]\n",
      "avenue : 13322 [ College Avenue, College Avenue, Keeler Avenue ,...]\n",
      "road : 3067 [ Gouldin Road, Primrose Road, Shasta Road ,...]\n",
      "drive : 2070 [ Laird Drive, Middlefield Drive, Skyline Drive ,...]\n",
      "way : 1649 [ Bancroft Way, Martin Luther King Jr Way, Orinda Way ,...]\n",
      "court : 824 [ Prescott Court, Prescott Court, Prescott Court ,...]\n",
      "boulevard : 823 [ West Hillsdale Boulevard, Fremont Boulevard, Treat Boulevard ,...]\n",
      "lane : 774 [ Laurel Lane, Laurel Lane, Arcade Lane ,...]\n",
      "place : 431 [ William Saroyan Place, Romolo Place, Bayview Place ,...]\n",
      "real : 421 [ South El Camino Real, El Camino Real, El Camino Real ,...]\n",
      "broadway : 397 [ Broadway, Broadway, Broadway ,...]\n",
      "alameda : 376 [ The Alameda, The Alameda, The Alameda ,...]\n",
      "circle : 167 [ Holly Park Circle, Columbia Circle, Columbia Circle ,...]\n",
      "ave : 87 [ Floribunda Ave, Paloma Ave, Grant Ave ,...]\n",
      "st : 86 [ Park St, S Delaware St, 16th St ,...]\n",
      "terrace : 85 [ Greenwood Terrace, Hawthorne Terrace, Hawthorne Terrace ,...]\n",
      "gardens : 57 [ Wildwood Gardens, Wildwood Gardens, Wildwood Gardens ,...]\n",
      "plaza : 40 [ Lakeshore Plaza, Civic Center Plaza, Mint Plaza ,...]\n",
      "blvd : 37 [ Skyline Blvd, Geary Blvd, Cipriani Blvd ,...]\n",
      "highway : 34 [ Bayshore Highway, Great Highway, Panoramic Highway ,...]\n",
      "ora : 34 [ Avenue Del Ora, Avenue Del Ora, Avenue Del Ora ,...]\n",
      "parkway : 31 [ Franklin Parkway, Discovery Parkway, Bridge parkway ,...]\n",
      "center : 27 [ Fort Mason Center, Seramonte Center, South Shore Center ,...]\n",
      "plz : 25 [ Woodside Plz, Woodside Plz, Woodside Plz ,...]\n",
      "square : 22 [ Shattuck Square, Jack London Square, Shattuck Square ,...]\n",
      "path : 18 [ Parnassus Path, Parnassus Path, Parnassus Path ,...]\n",
      "mason : 16 [ Fort Mason, Fort Mason, Fort Mason ,...]\n",
      "st. : 16 [ Sutter St., Halleck St., Divisadero St. ,...]\n",
      "las : 16 [ Alameda De Las, Alameda De Las, Alameda De Las ,...]\n",
      "alley : 14 [ Hodges Alley, Hodges Alley, Hodges Alley ,...]\n",
      "h : 12 [ Avenue H, Avenue H, Avenue H ,...]\n",
      "walk : 12 [ Rose Walk, Rose Walk, Terrace Walk ,...]\n",
      "embarcadero : 11 [ The Embarcadero, The Embarcadero, Embarcadero ,...]\n",
      "dr : 10 [ Chateau Dr, California Dr, Hillside Dr ,...]\n",
      "rd : 10 [ Rollins Rd, Ascot Rd, Marshlands Rd ,...]\n",
      "loop : 10 [ Hamlin Loop, Hamlin Loop, Hamlin Loop ,...]\n",
      "ave. : 9 [ San Carlos Ave., Menalto Ave., Fairmount Ave. ,...]\n",
      "cres : 7 [ Wellesley Cres, Wellesley Cres, Wellesley Cres ,...]\n",
      "park : 7 [ South Park, South Park, South Park ,...]\n",
      "pulgas : 7 [ Alameda de Las Pulgas, Alamed de las Pulgas, Alameda De Las Pulgas ,...]\n",
      "polk : 6 [ Polk, Polk, Polk ,...]\n",
      "north : 6 [ Cabrillo Highway North, Mission Bay Boulevard North, Mission Bay Boulevard North ,...]\n",
      "southgate : 6 [ Southgate, Southgate, Southgate ,...]\n",
      "clemente : 6 [ San Clemente, San Clemente, San Clemente ,...]\n",
      "a : 5 [ Pier 50 A, Adrian Court, Suite A, Upton St #A ,...]\n",
      "d : 4 [ Avenue D, Avenue D, Avenue D ,...]\n",
      "bridgeway : 4 [ Bridgeway, Bridgeway, Bridgeway ,...]\n",
      "post : 3 [ Post, Post, Post ,...]\n",
      "ic : 3 [ Ne Quad I-280 / Edgewood Rd Ic, Nw Quad Sr 84 / Ardenwood Blvd Ic, Se Quad Sr 92 / Ralston Ic ,...]\n",
      "powell : 3 [ Bay and Powell, Powell, Powell ,...]\n",
      "palms : 3 [ Avenue of the Palms, Avenue of the Palms, Avenue of the Palms ,...]\n",
      "ness : 3 [ Van Ness, Van Ness, Van Ness ,...]\n",
      "mission : 2 [ Mission, Mission ]\n",
      "east : 2 [ Francisco Boulevard East, Buena Vista Avenue East ]\n",
      "steps : 2 [ Bancroft Steps, Bancroft Steps ]\n",
      "crescent : 2 [ Wellesley Crescent, Clarendon Crescent ]\n",
      "dr. : 2 [ Grandview Dr., Monarch Bay Dr. ]\n",
      "ct : 2 [ Prescott Ct, Prescott Ct ]\n",
      "columbus : 2 [ Columbus, Columbus ]\n",
      "ctr : 2 [ Tanforan Shopping Ctr, Linda Mar Shppng Ctr ]\n",
      "rhein : 2 [ Stein Am Rhein, Stein Am Rhein ]\n",
      "via : 2 [ La Casa Via, La Casa Via ]\n",
      "hwy : 2 [ Redwood Hwy, 40 Shoreline Hwy ]\n",
      "market/noe : 2 [ Market/Noe, Market/Noe ]\n",
      "leimert : 2 [ Leimert, Leimert ]\n",
      "west : 2 [ Buena Vista Avenue West, Buena Vista Avenue West ]\n",
      "730 : 2 [ Sansome Street Suite 730, Sansome Street Ste 730 ]\n",
      "2 : 2 [ 2, San Francisco Bicycle Route 2 ]\n",
      "avenie : 2 [ Garvin Avenie, Garvin Avenie ]\n",
      "pl : 2 [ San Francisco/Oakland Bridge Toll Pl, Waverly Pl ]\n",
      "building : 2 [ Ferry Building, Ferry Building ]\n",
      "sutter : 2 [ Sutter, Sutter ]\n",
      "int : 2 [ 012 Mi Ne Of Sr 1 / Linda Mar Blvd Int, Se Quad Sr 1 / Crespi Dr Int ]\n",
      "lugano : 2 [ Via Lugano, Via Lugano ]\n",
      "floor : 2 [ Montgomery Street, 2nd Floor, Twin Dolphin Drive 6th Floor ]\n",
      "boulvard : 2 [ Alemany Boulvard, Alemany Boulvard ]\n",
      "blvd. : 2 [ East Francisco Blvd., Geary Blvd. ]\n",
      "bluxome : 1 [ Bluxome ]\n",
      "monte : 1 [ North Via Monte ]\n",
      "sobrante : 1 [ Camino Sobrante ]\n",
      "3658 : 1 [ Market Street Suite 3658 ]\n",
      "harrison : 1 [ Harrison ]\n",
      "cut : 1 [ Short Cut ]\n",
      "ln : 1 [ Yerba Buena Ln ]\n",
      "clement : 1 [ Clement ]\n",
      "market/castro : 1 [ Market/Castro ]\n",
      "wedemeyer : 1 [ Wedemeyer ]\n",
      "15 : 1 [ Doolittle Dr, Suite 15 ]\n",
      "24th : 1 [ 24th ]\n",
      "hall : 1 [ McCone Hall ]\n",
      "rd. : 1 [ Alpine Rd. ]\n",
      "bay : 1 [ Bay ]\n",
      "15th : 1 [ 15th ]\n",
      "rock : 1 [ Mission Rock ]\n",
      "view : 1 [ Norwood View ]\n",
      "leslie : 1 [ Leslie ]\n",
      "boulavard : 1 [ Alemany Boulavard ]\n",
      "hill : 1 [ California Street ( tra Polk St & Larkin St ) a Nob Hill ]\n",
      "410 : 1 [ 18th Street Ste 410 ]\n",
      "abenue : 1 [ Columbus Abenue ]\n",
      "ln. : 1 [ Bont Ln. ]\n",
      "california : 1 [ California ]\n",
      "marina : 1 [ San Leandro Marina ]\n",
      "spencer : 1 [ E & W Of  Us 101 @ Monte Mar & Spencer ]\n",
      "alto : 1 [ Camino Alto ]\n",
      "loma : 1 [ La Loma ]\n",
      "900 : 1 [ California Street #900 ]\n",
      "arguello : 1 [ Arguello ]\n",
      "geary : 1 [ Geary ]\n",
      "fillmore : 1 [ Fillmore ]\n",
      "bradshaw : 1 [ Bradshaw ]\n",
      "pablo : 1 [ Camino Pablo ]\n",
      "100 : 1 [ Woodside Road, Suite 100 ]\n",
      "market : 1 [ Market ]\n",
      "170 : 1 [ California Street, Suite 170 ]\n",
      "telegraph : 1 [ 3605 Telegraph ]\n",
      "c-134 : 1 [ Holloway Avenue, Ste C-134 ]\n",
      "10675 : 1 [ 10675 ]\n",
      "king : 1 [ King ]\n",
      "i-580 : 1 [ E Of Center St @ I-580 ]\n",
      "b : 1 [ Pier 50 B ]\n",
      "f : 1 [ Avenue F ]\n",
      "mall : 1 [ Pacific Avenue Mall ]\n",
      "townsend : 1 [ Townsend ]\n",
      "9th : 1 [ 9th ]\n",
      "steet : 1 [ Guerrero Steet ]\n",
      "3.2 : 1 [ ALA 84 PM 3.2 ]\n",
      "bridge : 1 [ Pier 1  SM- Hayward Bridge ]\n",
      "wharf : 1 [ Fishermans Wharf ]\n",
      "155 : 1 [ Woodside Road, Suite 155 ]\n",
      "m : 1 [ Avenue M ]\n",
      "4.5 : 1 [ SF 80 PM 4.5 ]\n",
      "12180142 : 1 [ 12180142 ]\n",
      "brannan : 1 [ Brannan ]\n",
      "judah : 1 [ Judah ]\n",
      "pine : 1 [ Pine ]\n",
      "1 : 1 [ W Of Us 101 @ Jct Sr 1 ]\n",
      "203 : 1 [ Bartlett Street #203 ]\n",
      "oakridge : 1 [ Oakridge ]\n",
      "schwerin : 1 [ Schwerin ]\n",
      "41276 : 1 [ Upton St 41276 ]\n",
      "488 : 1 [ Market Street #488 ]\n",
      "arrowhead : 1 [ lake arrowhead ]\n",
      "i-580) : 1 [ N Side Of Foothill Blvd @ John Dr (Near I-580) ]\n",
      "e : 1 [ Avenue E ]\n",
      "41st : 1 [ 41st ]\n",
      "ashfield : 1 [ Ashfield ]\n",
      "lindbergh : 1 [ Ne Quad Us 101 / 3rd Ave Off Lindbergh ]\n",
      "blvd, : 1 [ Nw Quad I-280 / Sr 35 Ic @ Jct Hayne Rd, Golf Course Dr, Skyline Blvd, ]\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "import re\n",
    "\n",
    "street_name_re = re.compile(r'\\b\\S+\\.?$', re.IGNORECASE)\n",
    "\n",
    "street_names = defaultdict(int)\n",
    "street_name_examples = defaultdict(list)\n",
    "\n",
    "for _, tag in ET.iterparse(xml_file):\n",
    "    if tag.tag == \"tag\" and tag.attrib['k'] == \"addr:street\":\n",
    "        street = tag.attrib['v']\n",
    "        match = street_name_re.search(street)\n",
    "        if match:\n",
    "            name = match.group().lower()\n",
    "            street_names[name] += 1\n",
    "            if street_names[name] <= 3:\n",
    "                street_name_examples[name].append(street)\n",
    "\n",
    "for k,v in sorted(street_names.items(), key=operator.itemgetter(1), reverse=True):\n",
    "    print k, ':', v, '[', ', '.join(street_name_examples[k]), (v>=3 and \",...]\" or ']')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the audit above, we see the common street names (ones that I expected to see) are:\n",
    "  * street\n",
    "  * avenue\n",
    "  * road\n",
    "  * way\n",
    "  * drive\n",
    "  * boulevard\n",
    "  * broadway\n",
    "  * lane\n",
    "  * plaza\n",
    "  * square\n",
    "  * parkway\n",
    "  * highway\n",
    "  * walk\n",
    "    \n",
    "Some common abbreviations are:\n",
    "\n",
    "  * st => street\n",
    "  * ave => avenue\n",
    "  * plz => plaza\n",
    "  * blvd => boulevard\n",
    "  * st => street\n",
    "  * dr => drive\n",
    "  * rd => road\n",
    "  * ave. => avenue\n",
    "  * dr. => drive\n",
    "  * hwy => highway\n",
    "  * blvd. => boulevard\n",
    "\n",
    "There are also some valid but uncommon street names (ones that I didn't expect to see):\n",
    "\n",
    "  * real : [ South El Camino Real, El Camino Real ,...]\n",
    "  * court : [ Prescott Court, Prescott Court ,...]\n",
    "  * place : [ William Saroyan Place, Romolo Place ,...]\n",
    "  * alameda : [ The Alameda, The Alameda ,...]\n",
    "  * circle : [ Holly Park Circle, Columbia Circle ,...]\n",
    "  * center : [ Fort Mason Center, Seramonte Center ,...]\n",
    "  * path : [ Parnassus Path, Parnassus Path ,...]\n",
    "  * terrace : [ Greenwood Terrace, Hawthorne Terrace ,...]\n",
    "  * embarcadero : [ The Embarcadero, The Embarcadero ,...]\n",
    "  \n",
    "The rest street names are either very uncommon erroneously formatted (e.g. `leimert : [ Leimert, Leimert ]`, `rock : [ Mission Rock ]`, `410 : [ 18th Street Ste 410 ]`, `h : [ Avenue H ]` etc.)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Clean the dataset and convert to JSON"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clean street names\n",
    "\n",
    "Based on audit above, we clean the street name with the following rules:\n",
    "  * keep the common street names, both common ones (e.g. `street`, `road`) and the uncommone ones (e.g. `real`, `embarcadero`);\n",
    "  * convert the abbreviation to full name, e.g. `st => street`, `blvd => boulevard`;\n",
    "  * drop the very uncommon or erroneously formatted names, e.g. `410 [ 18th Street Ste 410 ]`, `rock : [ Mission Rock ]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "common_types = [\"street\", \"avenue\", \"road\", \"way\", \"drive\",\n",
    "                \"boulevard\", \"broadway\", \"lane\", \"plaza\", \"square\",\n",
    "                \"parkway\", \"highway\", \"walk\"]\n",
    "uncommon_types = [\"real\", \"court\", \"place\", \"alameda\", \"circle\",\n",
    "                  \"center\", \"path\", \"terrace\", \"embarcadero\"]\n",
    "abbreviations = {\"st\": \"street\",\n",
    "                 \"ave\": \"avenue\",\n",
    "                 \"plz\": \"plaza\",\n",
    "                 \"blvd\": \"boulevard\",\n",
    "                 \"st\": \"street\",\n",
    "                 \"dr\": \"drive\",\n",
    "                 \"rd\": \"road\",\n",
    "                 \"ave.\": \"avenue\",\n",
    "                 \"dr.\": \"drive\",\n",
    "                 \"hwy\": \"highway\",\n",
    "                 \"blvd.\": \"boulevard\"}\n",
    "\n",
    "def clean_street_name(street_name):\n",
    "    \"\"\"Clean the street name:\n",
    "    * for valid street types (common or nuncommon), name is unchanged;\n",
    "    * abbreviated street type will be expanded;\n",
    "    * for all other cases (invalid or erroneous), return `None`.\"\"\"\n",
    "    m = street_name_re.search(street_name)\n",
    "    if m:\n",
    "        street_type = m.group().lower()\n",
    "        if street_type in common_types or street_type in uncommon_types:\n",
    "            # Valid street type, no change need to be made.\n",
    "            return street_name\n",
    "        if street_type in abbreviations:\n",
    "            # Abbreviated street type need to be expanded.\n",
    "            return street_name_re.sub(abbreviations[street_type], street_name)\n",
    "    # In all other cases (invalid or erroneous format), return None.\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Address dictionary\n",
    "\n",
    "We create an address dictionary from the tags of an xml element as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_element_address(element):\n",
    "    \"\"\"For a given element in the xml, create an `address` dictionary\n",
    "    with the following fields: `housenumber`, `street`, `city` and `postcode`,\n",
    "    and the `street` field will be cleaned by `clean_street_name`.\"\"\"\n",
    "    address = {}\n",
    "    for tag in element:\n",
    "        for k in [\"housenumber\", \"city\", \"postcode\"]:\n",
    "            if tag.attrib.get('k') == \"addr:\" + k:\n",
    "                address[k] = tag.attrib['v']\n",
    "        if tag.attrib.get('k') == \"addr:street\":\n",
    "            street_name = clean_street_name(tag.attrib['v'])\n",
    "            if street_name:\n",
    "                address[\"street\"] = street_name\n",
    "    return address"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Created dictionary\n",
    "\n",
    "Similary, we create a `created` dictionary from the attribute of each element (`node`, `way` or `relation`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_element_created(elem):\n",
    "    \"\"\"Get a 'created' dictionary from an element, that has the following keys:\n",
    "    'version', 'changeset', 'timestamp', 'uid', 'user'.\"\"\"\n",
    "    created = {}\n",
    "    for k in [\"version\", \"changeset\", \"timestamp\", \"uid\", \"user\"]:\n",
    "        if k in elem.attrib:\n",
    "            created[k] = elem.attrib[k]\n",
    "    return created"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert the xml element to dictionary\n",
    "\n",
    "Now we are ready to convert each xml element (`node`, `way` or `relation`) into a \"json-ready\" dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def xml_to_json_helper(elem, dst):\n",
    "    \"\"\"A helper function for converting element to json-ready dictionary.\n",
    "    This will put the common attribute, e.g. `created`, `address`, and\n",
    "    tags into the `dst` dictionary.\"\"\"\n",
    "    dst[\"created\"] = get_element_created(elem)\n",
    "    dst[\"address\"] = get_element_address(elem)\n",
    "    # Append non-address tags.\n",
    "    for tag in elem:\n",
    "        if 'k' in tag.attrib and not tag.attrib['k'].startswith('addr:'):\n",
    "            dst[tag.attrib['k']] = tag.attrib['v']\n",
    "    return dst\n",
    "\n",
    "\n",
    "def shape_node(elem):\n",
    "    \"\"\"Convert a `node` element to a json-ready dictionary.\"\"\"\n",
    "    node = {\"element_type\": \"node\"}\n",
    "    xml_to_json_helper(elem, node)\n",
    "    # `id` and `coord` attributes.\n",
    "    node[\"id\"] = elem.attrib[\"id\"]\n",
    "    node[\"coord\"] = [float(elem.attrib[\"lat\"]), \n",
    "                     float(elem.attrib[\"lon\"])]\n",
    "    return node\n",
    "\n",
    "\n",
    "def shape_way(elem):\n",
    "    \"\"\"Convert a `way` element to a json-ready dictionary.\"\"\"\n",
    "    way = {\"element_type\": \"way\"}\n",
    "    xml_to_json_helper(elem, way)\n",
    "    # node references.\n",
    "    way[\"node_refs\"] = []\n",
    "    for nd in elem:\n",
    "        if nd.tag == \"nd\":\n",
    "            way[\"node_refs\"].append(nd.attrib[\"ref\"])\n",
    "    return way\n",
    "\n",
    "\n",
    "def shape_relation(elem):\n",
    "    \"\"\"Convert a `relation` element to a json-ready dictionary.\"\"\"\n",
    "    relation = {\"element_type\": \"relation\"}\n",
    "    xml_to_json_helper(elem, relation)\n",
    "    # members.\n",
    "    relation[\"members\"] = []\n",
    "    for member in elem:\n",
    "        if member.tag == \"member\":\n",
    "            md = {}\n",
    "            for k in [\"type\", \"ref\", \"role\"]:\n",
    "                if k in member.attrib:\n",
    "                    md[k] = member.attrib[k]\n",
    "            relation[\"members\"].append(md)\n",
    "    return relation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can iterate through the xml file, convert each top-level element (`node`, `way` or `relation`) to a json-ready dictionary and dump into a json file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import xml.etree.cElementTree as ET\n",
    "\n",
    "xml_file = \"data/san-francisco_california.osm\"\n",
    "json_file = xml_file + \".json\"\n",
    "\n",
    "with open(json_file, 'w') as f:\n",
    "    for _, elem in ET.iterparse(xml_file):\n",
    "        # Convert the element to json dictionary according to type.\n",
    "        if elem.tag == \"node\":\n",
    "            j = shape_node(elem)\n",
    "        elif elem.tag == \"way\":\n",
    "            j = shape_way(elem)\n",
    "        elif elem.tag == \"relation\":\n",
    "            j = shape_relation(elem)\n",
    "        else:\n",
    "            j = None\n",
    "        # Dump the json dictionary to file.\n",
    "        if j:\n",
    "            f.write(json.dumps(j) + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 Import into a MangoDB database and run queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import data and setup client\n",
    "\n",
    "First we instantiate a mongodb daemon process, using a local `db/` directory as database path.\n",
    "\n",
    "    mkdir -p `pwd`/db\n",
    "    mongod -dbpath `pwd`/db\n",
    "\n",
    "Then we can import the converted json file into the database using `mongoimport`.\n",
    "\n",
    "    mongoimport --db openstreetmap --collection sanfrancisco --drop \\\n",
    "                 --file data/san-francisco_california.osm.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use `pymongo` to interact with the database. A client can be setup as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "\n",
    "client = MongoClient()\n",
    "db = client.openstreetmap\n",
    "collection = db.sanfrancisco"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Running queries\n",
    "\n",
    "Count number of `node`s, `way`s and `relation`s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of <node>s: 3018836\n",
      "Number of <way>s: 324910\n",
      "Number of <relation>s: 3322\n"
     ]
    }
   ],
   "source": [
    "print \"Number of <node>s:\", collection.find({\"element_type\":\"node\"}).count()\n",
    "print \"Number of <way>s:\", collection.find({\"element_type\":\"way\"}).count()\n",
    "print \"Number of <relation>s:\", collection.find({\"element_type\":\"relation\"}).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Count number of distinct users, and show the top 10 users in  terms of number of contributed entries. From the results we can see the top 6 users contribute more than 100,0000 entries each, and the top contributor has 10 times more contributions than the number 7 contributor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of distinct users: 1970\n",
      "Top contributors:\n",
      "{u'count': 730014, u'_id': u'ediyes'}\n",
      "{u'count': 561447, u'_id': u'Luis36995'}\n",
      "{u'count': 421017, u'_id': u'Rub21'}\n",
      "{u'count': 337422, u'_id': u'oldtopos'}\n",
      "{u'count': 137380, u'_id': u'KindredCoda'}\n",
      "{u'count': 117709, u'_id': u'DanHomerick'}\n",
      "{u'count': 72845, u'_id': u'nmixter'}\n",
      "{u'count': 57892, u'_id': u'dchiles'}\n",
      "{u'count': 53922, u'_id': u'oba510'}\n",
      "{u'count': 52657, u'_id': u'brentengust'}\n"
     ]
    }
   ],
   "source": [
    "print \"Number of distinct users:\", len(collection.distinct(\"created.user\"))\n",
    "\n",
    "print \"Top contributors:\"\n",
    "cursor = collection.aggregate([\n",
    "        {\"$group\": {\"_id\": \"$created.user\", \"count\": {\"$sum\":1}}},\n",
    "        {\"$sort\": {\"count\": -1}},\n",
    "        {\"$limit\": 10}])\n",
    "for c in cursor:\n",
    "    print c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the most common amenties. We see that the number 1 is \"parking\", followed by \"restaurant\", which is quite respected in our San Francisco dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{u'count': 3641, u'_id': u'parking'}\n",
      "{u'count': 2320, u'_id': u'restaurant'}\n",
      "{u'count': 1316, u'_id': u'school'}\n",
      "{u'count': 1086, u'_id': u'place_of_worship'}\n",
      "{u'count': 836, u'_id': u'fire_hydrant'}\n",
      "{u'count': 716, u'_id': u'cafe'}\n",
      "{u'count': 640, u'_id': u'post_box'}\n",
      "{u'count': 628, u'_id': u'bench'}\n",
      "{u'count': 512, u'_id': u'fast_food'}\n",
      "{u'count': 443, u'_id': u'bicycle_parking'}\n"
     ]
    }
   ],
   "source": [
    "cursor = collection.aggregate([\n",
    "        {\"$match\": {\"amenity\": {\"$exists\":1}}},\n",
    "        {\"$group\": {\"_id\":\"$amenity\", \"count\":{\"$sum\":1}}},\n",
    "        {\"$sort\": {\"count\":-1}},\n",
    "        {\"$limit\": 10}])\n",
    "for c in cursor:\n",
    "    print c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As an additional exploration, we check the most common street names in the city. Note that the street names has been cleaned in our previous step. The results below show the number 1 common street name is \"El Camino Real\", which is a quite unique street name, followed by \"Broadway\", which is a more common name across United States."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{u'count': 408, u'_id': u'El Camino Real'}\n",
      "{u'count': 392, u'_id': u'Broadway'}\n",
      "{u'count': 337, u'_id': u'Alameda'}\n",
      "{u'count': 334, u'_id': u'Church Street'}\n",
      "{u'count': 322, u'_id': u'Jefferson Avenue'}\n",
      "{u'count': 309, u'_id': u'Sanchez Street'}\n",
      "{u'count': 296, u'_id': u'24th Street'}\n",
      "{u'count': 296, u'_id': u'San Pablo Avenue'}\n",
      "{u'count': 283, u'_id': u'Roosevelt Avenue'}\n",
      "{u'count': 240, u'_id': u'Hudson Street'}\n"
     ]
    }
   ],
   "source": [
    "cursor = collection.aggregate([\n",
    "        {\"$match\": {\"address.street\": {\"$exists\":1}}},\n",
    "        {\"$group\": {\"_id\": \"$address.street\", \"count\": {\"$sum\":1}}},\n",
    "        {\"$sort\": {\"count\": -1}},\n",
    "        {\"$limit\":10}])\n",
    "for c in cursor:\n",
    "    print c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step Five - Document your Work\n",
    "----------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Majority of documentation can be found in the previous section. Below are a few general thoughts about the dataset and the data wrangling process.\n",
    "\n",
    "* First, I think openstreetmap is a great dataset with large amount of information, and I really appreciate the creators making it publicly available. However, during the analyzing, I also notice that the dataset is quite noisy, with quite a few entries that are invalid or erroneously formatted (e.g. the large number of street names that occur only once or twice are mostly erroneous). This is understandable because most of the data come from user input (which leads to the success of the dataset), but I believe a post scanning and trimming by professionals will make the dataset even stronger.\n",
    "* One lesson I learned from this project is that auditing is a very important step for data wrangling. During the auditing, I can get a sense of data distributions, validity of assumptions I made, and possible errors from the dataset itself. It avoids a lot of errors and debugging in the cleaning and converting step.\n",
    "* Lastly, I see the power of a database management system (mongodb in this case). After importing the data into mongodb, querying and analyzing is orders of mangnitude faster than similar processing the raw xml file. The time spent cleaning and importing the data into a database management system is ver"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
